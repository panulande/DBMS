
# sigmoid(z)=1/(1+e^-z)
#tanh(z)=(e^z-e^-z)/(e^z+e^-z)
#ReLU(rectified linear unit) z if input it positive
                            # 0 otherwise
#Leaky ReLU
    #LeakyReLU(z)=z, z>0
                #az otherwise
#transferring some negative fraction value

#Design a dataset of students that contain SSC%, HSC%, HSC Math, 1st sem SGP, 2nd sem SGP, 3rd sem SGP, 4th sem SGP

#X 10x6
#Y 10x1

design 3 layer NN 
layer 1      layer2      layer3(only 1 neuron)